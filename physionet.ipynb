{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "direct-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "photographic-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for downloading of Physionet data (challenge 2012)\n",
    "class PhysioNet(object):\n",
    "\n",
    "    urls = [\n",
    "        'https://physionet.org/files/challenge-2012/1.0.0/set-a.tar.gz?download',\n",
    "        'https://physionet.org/files/challenge-2012/1.0.0/set-b.tar.gz?download',\n",
    "    ]\n",
    "\n",
    "    outcome_urls = ['https://physionet.org/files/challenge-2012/1.0.0/Outcomes-a.txt']\n",
    "\n",
    "    params = [\n",
    "        'Age', 'Gender', 'Height', 'ICUType', 'Weight', 'Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN',\n",
    "        'Cholesterol', 'Creatinine', 'DiasABP', 'FiO2', 'GCS', 'Glucose', 'HCO3', 'HCT', 'HR', 'K', 'Lactate', 'Mg',\n",
    "        'MAP', 'MechVent', 'Na', 'NIDiasABP', 'NIMAP', 'NISysABP', 'PaCO2', 'PaO2', 'pH', 'Platelets', 'RespRate',\n",
    "        'SaO2', 'SysABP', 'Temp', 'TroponinI', 'TroponinT', 'Urine', 'WBC'\n",
    "    ]\n",
    "\n",
    "    params_dict = {k: i for i, k in enumerate(params)}\n",
    "\n",
    "    labels = [ \"SAPS-I\", \"SOFA\", \"Length_of_stay\", \"Survival\", \"In-hospital_death\" ]\n",
    "    labels_dict = {k: i for i, k in enumerate(labels)}\n",
    "\n",
    "    def __init__(self, root, train=True, download=False,\n",
    "        quantization = 0.1, n_samples = None, device = torch.device(\"cpu\")):\n",
    "\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.reduce = \"average\"\n",
    "        self.quantization = quantization\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found. You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            data_file = self.training_file\n",
    "        else:\n",
    "            data_file = self.test_file\n",
    "\n",
    "        if device == torch.device(\"cpu\"):\n",
    "            self.data = torch.load(os.path.join(self.processed_folder, data_file), map_location='cpu')\n",
    "            self.labels = torch.load(os.path.join(self.processed_folder, self.label_file), map_location='cpu')\n",
    "        else:\n",
    "            self.data = torch.load(os.path.join(self.processed_folder, data_file))\n",
    "            self.labels = torch.load(os.path.join(self.processed_folder, self.label_file))\n",
    "\n",
    "        if n_samples is not None:\n",
    "            self.data = self.data[:n_samples]\n",
    "            self.labels = self.labels[:n_samples]\n",
    "\n",
    "\n",
    "    def download(self):\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "        os.makedirs(self.processed_folder, exist_ok=True)\n",
    "\n",
    "        # Download outcome data, process it and save it (Outcomes-a.pt)\n",
    "        for url in self.outcome_urls:\n",
    "            filename = url.rpartition('/')[2]\n",
    "            download_url(url, self.raw_folder, filename, None)\n",
    "\n",
    "            txtfile = os.path.join(self.raw_folder, filename)\n",
    "            with open(txtfile) as f:\n",
    "                lines = f.readlines()\n",
    "                outcomes = {}\n",
    "                for l in lines[1:]:\n",
    "                    l = l.rstrip().split(',')\n",
    "                    record_id = l[0]\n",
    "                    labels = np.array(l[1:]).astype(float)\n",
    "                    outcomes[record_id] = torch.Tensor(labels).to(self.device)\n",
    "\n",
    "                torch.save(\n",
    "                    outcomes,\n",
    "                    os.path.join(self.processed_folder, filename.split('.')[0] + '.pt')\n",
    "                )\n",
    "        \n",
    "        # download data (sets a and b)\n",
    "        for url in self.urls:\n",
    "            filename = (url.rpartition('/')[2]).split(\"?\")[0]\n",
    "            download_url(url, self.raw_folder, filename, None)\n",
    "            tar = tarfile.open(os.path.join(self.raw_folder, filename), \"r:gz\")\n",
    "            tar.extractall(self.raw_folder)\n",
    "            tar.close()\n",
    "\n",
    "            print('Processing {}...'.format(filename))\n",
    "            \n",
    "            \n",
    "        # read the file\n",
    "            dirname = os.path.join(self.raw_folder, filename.split('.')[0])\n",
    "            patients = []\n",
    "            total = 0\n",
    "            for txtfile in os.listdir(dirname):\n",
    "                record_id = txtfile.split('.')[0]\n",
    "                with open(os.path.join(dirname, txtfile)) as f:\n",
    "                    lines = f.readlines()\n",
    "                    prev_time = 0\n",
    "                    tt = [0.]\n",
    "                    vals = [torch.zeros(len(self.params)).to(self.device)]\n",
    "                    mask = [torch.zeros(len(self.params)).to(self.device)]\n",
    "                    nobs = [torch.zeros(len(self.params))]\n",
    "                    for l in lines[1:]:\n",
    "                        total += 1\n",
    "                        time, param, val = l.split(',')\n",
    "                        # Time in hours\n",
    "                        time = float(time.split(':')[0]) + float(time.split(':')[1]) / 60.\n",
    "                        # round up the time stamps (up to 6 min by default)\n",
    "                        # used for speed -- we actually don't need to quantize it in Latent ODE\n",
    "                        time = round(time / self.quantization) * self.quantization\n",
    "\n",
    "                        if time != prev_time:\n",
    "                            tt.append(time)\n",
    "                            vals.append(torch.zeros(len(self.params)).to(self.device))\n",
    "                            mask.append(torch.zeros(len(self.params)).to(self.device))\n",
    "                            nobs.append(torch.zeros(len(self.params)).to(self.device))\n",
    "                            prev_time = time\n",
    "\n",
    "                        if param in self.params_dict:\n",
    "                            #vals[-1][self.params_dict[param]] = float(val)\n",
    "                            n_observations = nobs[-1][self.params_dict[param]]\n",
    "                            if self.reduce == 'average' and n_observations > 0:\n",
    "                                prev_val = vals[-1][self.params_dict[param]]\n",
    "                                new_val = (prev_val * n_observations + float(val)) / (n_observations + 1)\n",
    "                                vals[-1][self.params_dict[param]] = new_val\n",
    "                            else:\n",
    "                                vals[-1][self.params_dict[param]] = float(val)\n",
    "                            mask[-1][self.params_dict[param]] = 1\n",
    "                            nobs[-1][self.params_dict[param]] += 1\n",
    "                        else:\n",
    "                            assert param == 'RecordID', 'Read unexpected param {}'.format(param)\n",
    "                tt = torch.tensor(tt).to(self.device)\n",
    "                vals = torch.stack(vals)\n",
    "                mask = torch.stack(mask)\n",
    "\n",
    "                labels = None\n",
    "                if record_id in outcomes:\n",
    "                    # Only training set has labels\n",
    "                    labels = outcomes[record_id]\n",
    "                    # Out of 5 label types provided for Physionet, take only the last one -- mortality\n",
    "                    labels = labels[4]\n",
    "\n",
    "                patients.append((record_id, tt, vals, mask, labels))\n",
    "\n",
    "            torch.save(\n",
    "                patients,\n",
    "                os.path.join(self.processed_folder, \n",
    "                    filename.split('.')[0] + \"_\" + str(self.quantization) + '.pt')\n",
    "            )\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "    def _check_exists(self):\n",
    "        for url in self.urls:\n",
    "            filename = url.rpartition('/')[2]\n",
    "\n",
    "            if not os.path.exists(\n",
    "                os.path.join(self.processed_folder, \n",
    "                    filename.split('.')[0] + \"_\" + str(self.quantization) + '.pt')\n",
    "            ):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def training_file(self):\n",
    "        return 'set-a_{}.pt'.format(self.quantization)\n",
    "\n",
    "    @property\n",
    "    def test_file(self):\n",
    "        return 'set-b_{}.pt'.format(self.quantization)\n",
    "\n",
    "    @property\n",
    "    def label_file(self):\n",
    "        return 'Outcomes-a.pt'\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_label(self, record_id):\n",
    "        return self.labels[record_id]\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Split: {}\\n'.format('train' if self.train is True else 'test')\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        fmt_str += '    Quantization: {}\\n'.format(self.quantization)\n",
    "        fmt_str += '    Reduce: {}\\n'.format(self.reduce)\n",
    "        return fmt_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads data and saves it in ...|data|Physionet|processed folder\n",
    "# set train=False to download the test data\n",
    "dataset = PhysioNet('data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "closed-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data, once downloaded\n",
    "train = torch.load(\"data/PhysioNet/processed/set-a_0.1.pt\")\n",
    "test  = torch.load(\"data/PhysioNet/processed/set-b_0.1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
